{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoder_Notes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNm1rb1vrVwUymizV63suDr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shibu778/MyNotebooks/blob/master/AutoEncoder_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4VqJIfsAcbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Link for tutorial - https://blog.keras.io/building-autoencoders-in-keras.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kZCV7kz-o5f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7faa9af-5c3e-46a6-c502-5ffa84b3612c"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxXmIAMz-_Xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFs62aj3_Ee0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b_GcHp-_U8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzLBPUEQ_cH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b484f1fa-585d-478f-bfd6-891f640db6f9"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmx3RqiE_i0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c4b32653-4d23-4791-b003-921d334f0c59"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VlPXbEj_46d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a78036e4-0685-4e6a-d5c1-441d654eb40c"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.3680 - val_loss: 0.2719\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2657 - val_loss: 0.2559\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2461 - val_loss: 0.2342\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2256 - val_loss: 0.2150\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2087 - val_loss: 0.2004\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1966 - val_loss: 0.1904\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1879 - val_loss: 0.1825\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1808 - val_loss: 0.1761\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1747 - val_loss: 0.1705\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1696 - val_loss: 0.1659\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1651 - val_loss: 0.1616\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1611 - val_loss: 0.1577\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1575 - val_loss: 0.1543\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1541 - val_loss: 0.1511\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1509 - val_loss: 0.1481\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1480 - val_loss: 0.1452\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1452 - val_loss: 0.1425\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1427 - val_loss: 0.1400\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1403 - val_loss: 0.1377\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1380 - val_loss: 0.1354\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1358 - val_loss: 0.1332\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1337 - val_loss: 0.1313\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1316 - val_loss: 0.1292\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1297 - val_loss: 0.1273\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1278 - val_loss: 0.1254\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1260 - val_loss: 0.1235\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1243 - val_loss: 0.1219\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1226 - val_loss: 0.1203\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1211 - val_loss: 0.1188\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1196 - val_loss: 0.1173\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1183 - val_loss: 0.1160\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1170 - val_loss: 0.1147\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1158 - val_loss: 0.1136\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1147 - val_loss: 0.1125\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1137 - val_loss: 0.1115\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1127 - val_loss: 0.1106\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1118 - val_loss: 0.1097\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1110 - val_loss: 0.1090\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1103 - val_loss: 0.1082\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1096 - val_loss: 0.1075\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1090 - val_loss: 0.1069\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1084 - val_loss: 0.1064\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1078 - val_loss: 0.1059\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1073 - val_loss: 0.1053\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1068 - val_loss: 0.1049\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.1064 - val_loss: 0.1045\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1060 - val_loss: 0.1041\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.1056 - val_loss: 0.1037\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1052 - val_loss: 0.1033\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1049 - val_loss: 0.1030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f041aa3dc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M41kc0PxABmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN0ez-7xAKuf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "3fdf33cb-dc16-407f-8784-65174edc03e8"
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE8vm4Y-AOkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "encoding_dim = 32\n",
        "\n",
        "input_img = Input(shape=(784,))\n",
        "# add a Dense layer with a L1 activity regularizer\n",
        "encoded = Dense(encoding_dim, activation='relu',\n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "236niy6PA-8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-tUymPZBFuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmAfVTNVBGIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ6jd-Ua_RtG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af8e290f-fca8-4b0a-c62f-25143b727f36"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.6727 - val_loss: 0.6484\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.6284 - val_loss: 0.6090\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.5916 - val_loss: 0.5749\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.5598 - val_loss: 0.5454\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.5323 - val_loss: 0.5198\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.5084 - val_loss: 0.4975\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.4875 - val_loss: 0.4780\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.4692 - val_loss: 0.4609\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.4531 - val_loss: 0.4457\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.4389 - val_loss: 0.4324\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.4262 - val_loss: 0.4205\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.4150 - val_loss: 0.4098\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.4049 - val_loss: 0.4003\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3959 - val_loss: 0.3918\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3877 - val_loss: 0.3840\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3804 - val_loss: 0.3771\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3737 - val_loss: 0.3707\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3676 - val_loss: 0.3649\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3621 - val_loss: 0.3596\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3570 - val_loss: 0.3548\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3524 - val_loss: 0.3503\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3481 - val_loss: 0.3463\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3442 - val_loss: 0.3425\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3406 - val_loss: 0.3390\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3372 - val_loss: 0.3357\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3341 - val_loss: 0.3327\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3312 - val_loss: 0.3299\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3285 - val_loss: 0.3273\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3259 - val_loss: 0.3249\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3236 - val_loss: 0.3226\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3213 - val_loss: 0.3204\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3193 - val_loss: 0.3184\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3173 - val_loss: 0.3165\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3155 - val_loss: 0.3147\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3138 - val_loss: 0.3131\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3121 - val_loss: 0.3115\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3106 - val_loss: 0.3100\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3091 - val_loss: 0.3085\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3077 - val_loss: 0.3072\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3064 - val_loss: 0.3059\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3052 - val_loss: 0.3047\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3040 - val_loss: 0.3035\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3029 - val_loss: 0.3024\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.3018 - val_loss: 0.3014\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.3008 - val_loss: 0.3004\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2998 - val_loss: 0.2994\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2989 - val_loss: 0.2985\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2980 - val_loss: 0.2976\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2971 - val_loss: 0.2968\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2963 - val_loss: 0.2960\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2955 - val_loss: 0.2952\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2948 - val_loss: 0.2945\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2941 - val_loss: 0.2938\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2934 - val_loss: 0.2931\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2927 - val_loss: 0.2925\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2921 - val_loss: 0.2918\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2915 - val_loss: 0.2912\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2909 - val_loss: 0.2906\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2903 - val_loss: 0.2901\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2898 - val_loss: 0.2895\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2892 - val_loss: 0.2890\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2887 - val_loss: 0.2885\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2882 - val_loss: 0.2880\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2877 - val_loss: 0.2875\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2873 - val_loss: 0.2871\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2868 - val_loss: 0.2867\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2864 - val_loss: 0.2862\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2860 - val_loss: 0.2858\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.2856 - val_loss: 0.2854\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2852 - val_loss: 0.2850\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.2848 - val_loss: 0.2846\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2844 - val_loss: 0.2843\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2841 - val_loss: 0.2839\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2837 - val_loss: 0.2836\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.2834 - val_loss: 0.2832\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2831 - val_loss: 0.2829\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2828 - val_loss: 0.2826\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2825 - val_loss: 0.2823\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2822 - val_loss: 0.2820\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2819 - val_loss: 0.2817\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2816 - val_loss: 0.2814\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2813 - val_loss: 0.2812\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2810 - val_loss: 0.2809\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2808 - val_loss: 0.2806\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2805 - val_loss: 0.2804\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2803 - val_loss: 0.2801\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2800 - val_loss: 0.2799\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2798 - val_loss: 0.2796\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2796 - val_loss: 0.2794\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2793 - val_loss: 0.2792\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2791 - val_loss: 0.2790\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2789 - val_loss: 0.2788\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2787 - val_loss: 0.2785\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2785 - val_loss: 0.2783\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2783 - val_loss: 0.2781\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2781 - val_loss: 0.2779\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.2779 - val_loss: 0.2778\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2777 - val_loss: 0.2776\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2775 - val_loss: 0.2774\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2774 - val_loss: 0.2772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0412b2a6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U03Ij5GLBGsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdZWetJoDBHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "befae6bc-8e89-4fa4-9f8c-498c38160cbf"
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_b4w6y_BbLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deep autoencoder\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5W4_FnuCMqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7474fd0-bb0c-4939-fce1-c38f1c44430b"
      },
      "source": [
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3333 - val_loss: 0.2637\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.2557 - val_loss: 0.2474\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.2387 - val_loss: 0.2295\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.2245 - val_loss: 0.2177\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.2115 - val_loss: 0.2056\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.2012 - val_loss: 0.1941\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1880 - val_loss: 0.1794\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1778 - val_loss: 0.1737\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1717 - val_loss: 0.1674\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1671 - val_loss: 0.1634\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1625 - val_loss: 0.1598\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1580 - val_loss: 0.1559\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1540 - val_loss: 0.1517\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1509 - val_loss: 0.1487\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1480 - val_loss: 0.1443\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1456 - val_loss: 0.1431\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1433 - val_loss: 0.1418\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1415 - val_loss: 0.1391\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.1399 - val_loss: 0.1367\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1384 - val_loss: 0.1362\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1368 - val_loss: 0.1345\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.1352 - val_loss: 0.1337\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.1337 - val_loss: 0.1325\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1319 - val_loss: 0.1306\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.1305 - val_loss: 0.1291\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.1290 - val_loss: 0.1277\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1277 - val_loss: 0.1279\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1266 - val_loss: 0.1259\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1254 - val_loss: 0.1226\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1243 - val_loss: 0.1240\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1233 - val_loss: 0.1207\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1223 - val_loss: 0.1205\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1213 - val_loss: 0.1196\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1205 - val_loss: 0.1196\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1195 - val_loss: 0.1175\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1189 - val_loss: 0.1173\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1182 - val_loss: 0.1168\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1174 - val_loss: 0.1151\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1170 - val_loss: 0.1146\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1162 - val_loss: 0.1144\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1158 - val_loss: 0.1167\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1152 - val_loss: 0.1115\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1147 - val_loss: 0.1132\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1143 - val_loss: 0.1119\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1139 - val_loss: 0.1133\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1133 - val_loss: 0.1113\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1128 - val_loss: 0.1120\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.1123 - val_loss: 0.1106\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1118 - val_loss: 0.1111\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1114 - val_loss: 0.1109\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1110 - val_loss: 0.1106\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1105 - val_loss: 0.1094\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1101 - val_loss: 0.1083\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1097 - val_loss: 0.1089\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1094 - val_loss: 0.1092\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1089 - val_loss: 0.1074\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1085 - val_loss: 0.1061\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1082 - val_loss: 0.1067\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1079 - val_loss: 0.1074\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1076 - val_loss: 0.1082\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1073 - val_loss: 0.1074\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1069 - val_loss: 0.1060\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1067 - val_loss: 0.1040\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1063 - val_loss: 0.1051\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1062 - val_loss: 0.1041\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1059 - val_loss: 0.1055\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1055 - val_loss: 0.1048\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1053 - val_loss: 0.1049\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1050 - val_loss: 0.1058\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1048 - val_loss: 0.1037\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1045 - val_loss: 0.1047\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1044 - val_loss: 0.1040\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1041 - val_loss: 0.1026\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1040 - val_loss: 0.1040\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1037 - val_loss: 0.1033\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1034 - val_loss: 0.1015\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1033 - val_loss: 0.1048\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1030 - val_loss: 0.1012\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1028 - val_loss: 0.1022\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1026 - val_loss: 0.1010\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1025 - val_loss: 0.1020\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1023 - val_loss: 0.1014\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1020 - val_loss: 0.1018\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1019 - val_loss: 0.1018\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1017 - val_loss: 0.1007\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1015 - val_loss: 0.1007\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1013 - val_loss: 0.1013\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1011 - val_loss: 0.0994\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1010 - val_loss: 0.0997\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1009 - val_loss: 0.1013\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1006 - val_loss: 0.1001\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1004 - val_loss: 0.1003\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1003 - val_loss: 0.0993\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1001 - val_loss: 0.0985\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0999 - val_loss: 0.0997\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0998 - val_loss: 0.0989\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0997 - val_loss: 0.0981\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0995 - val_loss: 0.0989\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0994 - val_loss: 0.0985\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0992 - val_loss: 0.1003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0412996240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SedhhRaCQEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPQtDSRbCUfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "bc1b0d3d-0a79-42f4-bb8f-ffe885ca86bf"
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4GHueUiCUbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional Autoencoder\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWm8Dx2gCUXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGL359j3CUSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "a6af66b8-554a-4fc3-c860-b20cafbbfa73"
      },
      "source": [
        "tensorboard --logdir=/tmp/autoencoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-d252ebf52f78>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir=/tmp/autoencoder\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQrLANR9CxCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e479614-8b93-4994-959e-3e68c43a7898"
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.2221 - val_loss: 0.1698\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 79s 1ms/step - loss: 0.1547 - val_loss: 0.1429\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1394 - val_loss: 0.1319\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1315 - val_loss: 0.1320\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 86s 1ms/step - loss: 0.1265 - val_loss: 0.1223\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1230 - val_loss: 0.1226\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1206 - val_loss: 0.1229\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1180 - val_loss: 0.1147\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1166 - val_loss: 0.1184\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1151 - val_loss: 0.1112\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1140 - val_loss: 0.1122\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 87s 1ms/step - loss: 0.1131 - val_loss: 0.1116\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1121 - val_loss: 0.1132\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1116 - val_loss: 0.1113\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1106 - val_loss: 0.1086\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1098 - val_loss: 0.1089\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1094 - val_loss: 0.1050\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1087 - val_loss: 0.1057\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1083 - val_loss: 0.1072\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 86s 1ms/step - loss: 0.1078 - val_loss: 0.1081\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1073 - val_loss: 0.1067\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1070 - val_loss: 0.1055\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1066 - val_loss: 0.1055\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1062 - val_loss: 0.1034\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1058 - val_loss: 0.1034\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1055 - val_loss: 0.1019\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 87s 1ms/step - loss: 0.1051 - val_loss: 0.1064\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1047 - val_loss: 0.1042\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1044 - val_loss: 0.1029\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1042 - val_loss: 0.1017\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1040 - val_loss: 0.1045\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1033 - val_loss: 0.1017\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1032 - val_loss: 0.1023\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1028 - val_loss: 0.1005\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 86s 1ms/step - loss: 0.1025 - val_loss: 0.1017\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1024 - val_loss: 0.1054\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1021 - val_loss: 0.1018\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1016 - val_loss: 0.1037\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1017 - val_loss: 0.0977\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1014 - val_loss: 0.1018\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1015 - val_loss: 0.0999\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 87s 1ms/step - loss: 0.1014 - val_loss: 0.1055\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1012 - val_loss: 0.1005\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1010 - val_loss: 0.0977\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1008 - val_loss: 0.0998\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1007 - val_loss: 0.0990\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1006 - val_loss: 0.1006\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1004 - val_loss: 0.0988\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1001 - val_loss: 0.0987\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 85s 1ms/step - loss: 0.1001 - val_loss: 0.0983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f041264c240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzyjylPkCykO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sArdQh4oCysh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUcPigZVCy0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Application to Image Denoising\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaxWSbsoDvl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmClbXGEDwKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (7, 7, 32)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb8LWHDHDwVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl1TKxWRDwRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sequence-to-sequence autoencoder\n",
        "from keras.layers import Input, LSTM, RepeatVector\n",
        "from keras.models import Model\n",
        "\n",
        "inputs = Input(shape=(timesteps, input_dim))\n",
        "encoded = LSTM(latent_dim)(inputs)\n",
        "\n",
        "decoded = RepeatVector(timesteps)(encoded)\n",
        "decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
        "\n",
        "sequence_autoencoder = Model(inputs, decoded)\n",
        "encoder = Model(inputs, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOnoCno5EEaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Variational Autoencoder\n",
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "h = Dense(intermediate_dim, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_sigma = Dense(latent_dim)(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQCJVznqEGWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
        "                              mean=0., std=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1PtmJHbEGx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_h = Dense(intermediate_dim, activation='relu')\n",
        "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
        "h_decoded = decoder_h(z)\n",
        "x_decoded_mean = decoder_mean(h_decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0bL4jbxEHPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# end-to-end autoencoder\n",
        "vae = Model(x, x_decoded_mean)\n",
        "\n",
        "# encoder, from inputs to latent space\n",
        "encoder = Model(x, z_mean)\n",
        "\n",
        "# generator, from latent space to reconstructed inputs\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "_h_decoded = decoder_h(decoder_input)\n",
        "_x_decoded_mean = decoder_mean(_h_decoded)\n",
        "generator = Model(decoder_input, _x_decoded_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf3dNy0sEHoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vae_loss(x, x_decoded_mean):\n",
        "    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n",
        "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
        "    return xent_loss + kl_loss\n",
        "\n",
        "vae.compile(optimizer='rmsprop', loss=vae_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ZxF5woEH6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "vae.fit(x_train, x_train,\n",
        "        shuffle=True,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09tjEpJ_F3DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6OU9BQlF8DV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display a 2D manifold of the digits\n",
        "n = 15  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# we will sample n points within [-15, 15] standard deviations\n",
        "grid_x = np.linspace(-15, 15, n)\n",
        "grid_y = np.linspace(-15, 15, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]]) * epsilon_std\n",
        "        x_decoded = generator.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}